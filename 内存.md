[toc]
# 内存相关

## 1. 内存分布和设计方式
每个进程都有自己的虚拟空间地址，可以映射到实际的物理内存。虚拟地址->物理地址
分段：虚拟地址里段号和段内偏移地址，通过段表来找到对应物理地址。缺点容易产生内存碎片，和swap分区频繁交换效率低
分页：linux下每页4K，对所有虚拟地址分页，通过页号和页内偏移地址去页表来找到对应物理地址。页表太大 4M
多级分页：利用局部性原理，二三级页表需要的时候才创建，大大节省页表空间
TLB:常访问内存加入
段页式管理： 逻辑段(bss,data,text等)，每段里面再分页
linux内核： 共用内核空间1G，用户空间3G(栈/文件映射(共享内存动态库)/堆/bss/data/text)-- 对内存地址都从0开始，屏蔽了intel cpu段式管理，才有多段式分页管理.  


```
struct mm_struct {
 ...
 unsigned long (*get_unmapped_area) (struct file *filp,
 unsigned long addr, unsigned long len,
 unsigned long pgoff, unsigned long flags);
 ...
 unsigned long mmap_base; /* base of mmap area */                     //memory mapping段的起始地址
 unsigned long task_size; /* size of task vm space */
 ...
 unsigned long start_code, end_code, start_data, end_data;            //text区，data区起止地址
 unsigned long start_brk, brk, start_stack;                           //start_brk 就是heap段起手地址，brk就是堆的当前地址(堆的分配就是移动brk指针)
                                                                      //[start_stack,end_stack) 栈的地址
 unsigned long arg_start, arg_end, env_start, env_end;                 
 ...
}
```
![](https://cdn.jsdelivr.net/gh/SylarHub/imageHost@master/img202305201223627.png)
//堆内存分配移动brk指针
//共享内存区分配用mmap将一个文件或者其它对象映射进内存，mmap只是在虚拟内存分配了地址空间，只有在第一次访问虚拟内存的时候才分配物理内存.

## 2. free时如何知道要释放的空间大小
有多种方式实现，比较常见的一种在释放内存的时候多分配4个字节空间用来保存空间大小，返回给用户时偏移size_t个字节。 
还有一种实现方式是基于chunk的管理。虚拟内存分为n个chunk. 每个chunk有固定大小(4k*n)，每次从虚拟内存按chunk分配，然后再chunk里进行小内存分配。chunk头部存放了管理结构，所以能知道free的尺寸。 chunk里分配算法又有众多，有一种是类似stl分配，空闲链表实现.

## 3. 内存分配大概
malloc算法众多，大体分为两个流派，一个是glibc下的ptmalloc为代表的隐藏头风格，第二个流派是tcmalloc和jemalloc为代表的位图风格。前者由于 分配的众多chunk隔的太远，不利于cache命中。所有第二种效率更高点.


## 4. STL alloc


主要理解内存分配和构造是分开的，还有二级配置器 减少内存碎片问题.
### 1.自定义一个内存分配器，简单实现一些功能
```


template<typename T>
class MyAlloc
{
public:
	typedef T value_type;
	typedef T* pointer;
	typedef const T * const_pointer;
	typedef T& reference;
	typedef const T& const_refernce;
	typedef size_t size_type;
	typedef ptrdiff_t difference_type;

	template<typename T>
	struct rebind { typedef MyAlloc<T> other; };

	template<typename T>
	MyAlloc(const MyAlloc<T>& other) throw() {};			//特别注意，需要一个泛化的拷贝构造函数

	MyAlloc() {};

	pointer allocate(size_type n, const void *hint = 0)
	{
		return __allocate((difference_type)n, pointer(0));
	}
	void deallocate(pointer p, size_type n)
	{
		return __deallocate1(p);
	}
	void construct(pointer p, const T& value)
	{
		__construct(p, value);
	}
	void destroy(pointer p) {  __destroy(p); }
	pointer address(reference x) { return pointer(&x); }
	const_pointer address(const_refernce x) { return const_pointer(&x); }
	size_type max_size()const { return size_type(UINT_MAX) / sizeof(T); }

	pointer __allocate(size_type n, const void *hint = 0)
	{
		cout << "内存分配" << endl;
		return static_cast<T*>(::operator new(n * sizeof(T)));
	}
	void  __deallocate1(pointer p){
		::operator delete(p);
		cout << "内存释放"  << endl;
	}
	void __construct(pointer p, const_refernce value)
	{
		new(p) T(value);
	}
	void __destroy(pointer p)
	{
		cout << "析构"  << endl;
		p->~T();
	}

	
};

int main(int argc, char* argv[])
{
	vector<Demo, MyAlloc<Demo>> v;
}

```
提供若干类型定义，构造析构接口和对象内存分配释放接口，以及拷贝构造函数泛化

### 2:  type_traits特化
对基本数据类型，进行特化，可以判断出需要构造，析构，是否是POD等。利用这些特性可以在构造析构分配释放等接口中特殊处理。
如：根据 类型是否是 has_trival_destructor，来确定是否调用析构函数(int 等类型不需要调用) 
如：针对拷贝，根据POD判断，直解copy或者构造
### 3. 内存分配策略
采取双层配置器
第一级：直接使用malloc和free
第二级：内存池 + 空闲链表  思想. 针对>128字节使用第一层，针对<128维护了16个自由链表(管理8.16.24..128字节)，负责各种小型内存下的配置. 
         存在问题1：配置器所有方法都是静态的，自由链表会一直占用内存，其他进程也用不了。第二 每次多分配一些内存，内存大小为8倍数。
```
//链表基本数据
union obj
{
    union obj * free_list_link;        //链表中下一个数据
    char data[0];                      //数据
}
//

obj * free_list[16];        //16组数据，每一组都是一个链表
```
![](https://cdn.jsdelivr.net/gh/SylarHub/imageHost@master/img202305201224964.png)
核心思路就是，预先分配一块大内存，标记可用开始点和结束点。  当通过二级分配器进行内存分配时，首先去free_list找到具体下表位置(上调至8倍数，找到对应索引)。如果对于的链表里有数据，直接分配给客户端。如果没有，直接去预分配的内存池里取空间（重新标记可用开始点）。内存池够用直接分配到链表中，内存池不够用话，重新分配2n个内存空间(如果分配失败还回去更大自己的链表里去分配)。(chunk_alloc接口).

## 5. glibc下的ptmalloc
malloc和new就是用这个内存分配策略. 不可能每次new free都和操作系统打交道，这样消耗大，需要个内存分配管理器进行统一管理，集中分配和释放.
下面主要参考这个链接 [20张图2万字长文带你了解ptmalloc](https://mp.weixin.qq.com/s/pdv5MMUQ9ACpeCpyGnxb1Q)

[ 内存管理器ptmalloc](https://www.cnblogs.com/peifx/p/16276832.html)
一句话概括，就是的基于chunk的分级空闲链表.


[最全解析](http://www.valleytalk.org/wp-content/uploads/2015/02/glibc内存管理ptmalloc源代码分析1.pdf)

### 5.1 分配区概念
一个进程的动态内存由分配区进行管理。首先一个进程拥有主分配区和多个副分配区(主分配区用sbrk和mmap分配，副分配区由mmap分配)。所有的分配区通过环形链表进行连接. 全局分配区可以由多个线程共享访问(每个分配区有个mutex),线程有自己私有的线程分配区(thread cache)，在static区分配了，属于线程独立。
 在线程中调用malloc进行内存分配时，首先去thread cache中寻找可分配内存，如果没有就去全局分配区寻找一个未加锁的分配区，进行内存分配。如果都锁了，就新分配一个分配区并加入环形链表中.(32位下最多有2*cpu核+1个分配区)
 每个分配区是 struct malloc_state 的一个实例
### 5.2 heap

![](vx_images/521944619234227.png)

进程内有多个分配区，一个分配区有多个堆。这些堆通过链表进行链接. 堆负责管理一块连续的虚拟内存，负责管理虚拟内存。 chunk就是实际的内存块
```
typedef struct _heap_info
{
  mstate ar_ptr;            /* Arena for this heap. */
  struct _heap_info *prev;  /* Previous heap. */
  size_t size;              /* Current size in bytes. */
  size_t mprotect_size;     /* Size in bytes that has been mprotected
                             PROT_READ|PROT_WRITE.  */
  /* Make sure the following data is properly aligned, particularly
     that sizeof (heap_info) + 2 * SIZE_SZ is a multiple of
     MALLOC_ALIGNMENT. */
  char pad[-6 * SIZE_SZ & MALLOC_ALIGN_MASK];
```
ar_ptr指向分配区，prev指向上一个堆
![](https://cdn.jsdelivr.net/gh/SylarHub/imageHost@master/img202305201225651.png)
### 5.3 chunk
chunk是 内存分配的基础结构，无论怎么分配，用什么方式分配，用户请求分配的空间就是一个chunk.chunk分非空闲和空闲(被用户使用)，如下图所示



![](https://cdn.jsdelivr.net/gh/SylarHub/imageHost@master/img202305201225705.png)

前一个chunk的size：通过当前位置偏移前一个chunk的位置，可以找到上一个chunk的位置，可以用于chunk之间合并
AMP：标志位，p=0标明是空闲的，m=1标明mmap分配的，a=0代表主分配区
fd/bk/fd_nextsize/bk_nextsize: 空闲链表才有相关定义，当非空闲时这些内如加入给用户分配的区域里. fd/bk作用是用于加入空闲chunk表链表,指向链表中前一个以及后一个chunk. fd_nextsize和bk_nextsize是用于指向下一个空闲的比当前size更大的chunk.


### 5.4 bins
bins就是空闲链表，用来组织管理空闲的chunk.  free进行内存释放时，直接放入bins中。在ptmalloc中，会将大小相似的chunk链接起来，叫做bin。总共有128个bin供ptmalloc使用. 分为以下几种fast bin/unsorted bin/small bin/big bin。这些bin本质上来说就是各种各样大小的chunk集合，都是各种空闲链表
```
struct malloc_state {
 mutex_t mutex;                 /* Serialize access. */
 int flags;                       /* Flags (formerly in max_fast). */
 #if THREAD_STATS
 /* Statistics for locking. Only used if THREAD_STATS is defined. */
 long stat_lock_direct, stat_lock_loop, stat_lock_wait;
 #endif
 mfastbinptr fastbins[NFASTBINS];    /* Fastbins */
 mchunkptr top;
 mchunkptr last_remainder;
 mchunkptr bins[NBINS  * 2];
 unsigned int binmap[BINMAPSIZE];   /* Bitmap of bins */
 struct malloc_state *next;           /* Linked list */
 INTERNAL_SIZE_T system_mem;           //Memory allocated from the system in this arena.
 INTERNAL_SIZE_T max_system_mem;
 };
```
分配区结构由上述组成。

fastbins： 由10个组成，每类的大小分别是8/16/24/../80，每个里面都是chunk链表，按LIFO顺序存储和插入.是malloc内存分配中最先去查找的位置，主要用于小内存分配。用户释放<64字节的内存，直接放入这里，同时并不改变P状态，可用于下次快速申请.
unsorted bin： 它使用的是bins数组里的第1个，是bins的一个缓冲区，fast bins合并后chunk或者释放大于max_fast的内存都会首先进入unsorted_bin。 任意大小的chunk都可以加入，FIFO。属于bins一个缓冲区
 small bin：小于512个字节的属于这类，使用的bins数组里第2个-第n个（总共62个），。每类的大小从16/24/32/..504/。从链表首部添加(free),从链表尾部释放(malloc)。在free时也会进行chunk合并加入unsorted bin中.
 large bin：对超过512字节的，都用大bin进行分配。也是用bins数组，共有62个，前32个是64字节为步长，再16个512字节为步长，在8个4096位步长，依次类推。Binmap记录了各个bin中是否为空,hash映射释放为空
 
上述是基本的bin，还有一些特殊的bin：
top：堆最上面的一段空间，它不属于任何bin。当所有的bin都无法满足分配要求时，就要从这块区域里来分配.top chunk相当于分配区的剩余内存空间,当我们分配一块堆内存时，top chunk是出于地址的最高处的. 

mmaped ：分配的内存特别大，>128K，需要mmap映射.
last remainder chunk: 比如申请一个small bin，没有对应的大小，只有通过fd_nextsize/bk_nextsize找到一个更大的chunk，然后拆分，一部分给用户，一部分放入unsorted chunk。这部分就是last remainder chunk。在small bin查找找不到对应的就可以去这里找.

### 5.5 malloc
![](https://cdn.jsdelivr.net/gh/SylarHub/imageHost@master/img202305201226244.png)

可以看出，在malloc进行内存分配，一步步从分配区，到堆，最终就是取合适的chunk里分配内存.

### 5.6 free
![](https://cdn.jsdelivr.net/gh/SylarHub/imageHost@master/img202305201226661.png)


内存free首先也要活得分配区的锁，依次判断 怎么加入各种chunk中. top_chunk移动才会回归内存给操作系统.ptmalloc收缩内存是从top chunk开始，如果与top chunk相邻的chunk不能释放，top chunk以下的chunk都无法释放

### 5.7 使用注意
后分配的内存先释放, 因为 ptmalloc 收缩内存是从 top chunk 开始, 如果与 top chunk 相邻的 chunk 不能释放, top chunk 以下的 chunk 都无法释放
大块内存用mmap
小块内存用malloc（brk），申请内存时并非立即真申请，释放时并非真释放
尽量只缓存临时使用的空闲小内存块
收缩堆的条件是当前free的块大小加上前后能合并chunk的大小大于64KB、，并且堆顶的大小达到阈值，才有可能收缩堆，把堆最顶端的空闲内存返回给操作系统
需要长期保持的内存块最好不要用ptmalloc来管理
不停的内存分配ptmalloc会对内存进行切割和合并，会导致一定的内存碎片
线程数的增加或频繁分配内存可能会增加副分配区，副分配区一旦分配不会释放,引起内存暴增


## 6. 高性能tcmalloc
google开源内存分，Thread Cache Alloc。一句话概括，基于span和object的多层级内存分配系统.
![](https://cdn.jsdelivr.net/gh/SylarHub/imageHost@master/img202305201226268.png)
### 6.1 基础概念

可以参考[tcmalloc源码分析](https://blog.csdn.net/weixin_42194701/article/details/124198891)
#### 6.2.1 span
首先page就是linux的分页机制，大部分是4K。span由多个连续的page构成。
spanList就是 由多个 同等page的 span 连接而成的链表
#### 6.2.2 object
一个span在逻辑上可以划分为多个同等大小的object。这就是最小对象。 (eg:一个span可以均等划分为16字节的object，也可以均等划分为24字节的object)
tcmalloc下提供了一个叫做sizeClass的静态数组，用于指定span可以划分为哪种
```
const SizeClassInfo SizeMap::kSizeClasses[SizeMap::kSizeClassesCount] = {
    // 这里的每一行 称之为SizeClass
    // <bytes>, <pages>, <batch size>    <fixed>
    // Object大小列，一次申请的page数，一次移动的objects数(内存申请或回收)
    {        0,       0,           0},  // +Inf%
    {        8,       1,          32},  // 0.59%
    {       16,       1,          32},  // 0.59%
    ...
     {   262144,      32,           2},  // 0.02%
 };
```

### 6.2 内存构成
tcmalloc内存分配主要分为三个层级

![](vx_images/523132517235773.png)


当给小对象（<256K）分配内存时，首先从threadCache中获取内存。如果不足再从对应的CenterFreeList获取内存，再获取不到从PageHeap里获取内存。
当给大对象分配内存时，直接从PageHeap里分配内存.
#### 6.2.1 ThreadCache
线程缓存，每个线程都有自己独立的ThreadCache，这也是多线程下tcmalloc效率高的原因之一。下面来看它的构成
```
class ThreadCache {
  // ...略
  FreeList list_[kNumClasses]; 
  // ...略
};
```
它由多个空闲链表组成，每个空闲链表由多个object组成。索引位置为1的空闲链表的object的大小为8字节，索引位置为2的空闲链表的object的大小为16字节。
这个数组也是由上面的SizeMap::kSizeClasses 数组 sizeClass决定。(分层级)

#### 6.2.2 CentralFreeList
中央缓存，由多个线程所共有。请求使用时用自旋锁加锁。这一块主要由TransferCacheManager进行管理
```
class TransferCacheManager {
  
 private:
  // freelist_是个数组
  // 元素的类型是上面的CentralFreeList
  // 元素的数量与 映射表 SizeClassInfo对应
  CentralFreeList freelist_[kNumClasses];
} ABSL_CACHELINE_ALIGNED;

class CentralFreeList {

 private:
  // 锁
  // 线程从此处获取内存 需要加锁 保证并发安全
  absl::base_internal::SpinLock lock_;

  // 对应上文提到的映射表SizeClassInfo中的某个索引值
  // 目的找到Span拆解为object时，object的大小等规则
  size_t size_class_;  
  // object的总数量
  size_t object_size_;
  // 一个Span持有的object的数量
  size_t objects_per_span_;
  // 一个Span持有的page的数量
  Length pages_per_span_;
 }
```
可以看出，TransferCacheManager由多个CentralFreeList集合组成。每个CentralFreeList都是实际管理的是Span，等分为若干个object
根据SizeMap::kSizeClasses 数组 (kNumClasses就是数组大小)，索引为1代表 当前的CentralFreeList下的 span具体由多少page，多少个object组成。

#### 6.2.3 HeapList
```
class PageHeap final : public PageAllocatorInterface {
 public:
​
 private:
  // 持有两个Span构成的双向链表
  struct SpanListPair {
    // Span构成的双向链表
    SpanList normal; 
    // Span构成的双向链表
    SpanList returned;
  };
​
  //  大对象的内存从这里分配(length >= kMaxPages)
  SpanListPair large_ ABSL_GUARDED_BY(pageheap_lock);
​
  // kMaxPages.raw_num()这么多个，由上面SpanListPair类型构成的数组
  SpanListPair free_[kMaxPages.raw_num()] ABSL_GUARDED_BY(pageheap_lock);
​
  // ...略
};

```
PageHeap由多个SpanListPair构成，SpanListPair又主要是spanlist，由多个span链接构成。
PageHeap索引为n代表对于的span有n个page.

#### 6.3 free时如何知道大小
linux按页分配，一页8k(2^13).根据内存地址右移13位可以得到PageID. 通过PageMap（raidxTree）找到对应的sizeClass数组.

###  6.3 windows下使用
下载[gperftools](https://github.com/gperftools/gperftools)项目，点击sln解决方案，全部编译可以生成动态库libtcmalloc_minimal.
使用的时候链接动态库即可，注意强制符号引用__tcmalloc

[如何使用](https://www.isvee.com/archives/1925)

## 7. xy内存池

利用空闲链表的思想，步长为4或8. eg:  步长为4下， 为 4/8/12/16/20/.../8K. 个 空闲链表， 每个空闲链表下都是均等chunk（长度+头部长)。
比如分配11个字节，向上取整到12，到索引值为3的地方 取一块chunk(12字节+头部). 如果此处没有，则分配8K均等分12字节。组成chunk链表挂载

节省(一天顶多也就几M)
不同分配池 分配释放问题
头部长度
内存监控默认开启：查看内存泄露问题


## 8. 线上内存问题
1：非法访问
   多次free
   指针分配空间，如结构体内指针,野指针等
   vector等越界访问
   迭代器失效(vector和map)
   字符串\0结尾等 strncpy
   指针判空
2：内存泄露
  基类析构函数虚函数
  new了没有delete
  
## 9. 问题
1.线上内存泄漏问题如何解决
2:内存池设计

## 10. 内存泄漏工具
### 10.1 日志
如逍遥情缘内存库，在内存分配和释放时进行统计，需要情况的话直接输出.

### 10.2 valgrind
linux下检测 内存泄漏利器，缺点是需要运行到具体demo。特例情况下不容易触发。

### 10.3 windlg + UMDH
windows内存泄漏检查神器
[UMDH使用](https://blog.csdn.net/greywolf0824/article/details/89208809) 

